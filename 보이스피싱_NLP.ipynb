{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "df759163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import audioread\n",
    "import numpy as np\n",
    "import resampy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "import warnings\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ec68433c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>wav</th>\n",
       "      <th>voice_fishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>내가 나한테 잘해주면 돼요.혹시 여러분들 자식들가운데?지금 손자 손녀키운다고 먹고 ...</td>\n",
       "      <td>1-converted.ogg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>운명을 바꿔 놓습니다.서울대 음대를 나왔는데요.서울대가 중요한 게 아닙니다.결국 이...</td>\n",
       "      <td>10-converted.ogg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>네, 감사합니다.네, 감사합니다.서울대 면접없는 판 모국입니다 검사대 여름말씀이신건...</td>\n",
       "      <td>100-converted.ogg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그러나 인류는 절대 내가 내 말에 절대 라는 용어를 여간 해서는 절대 안 된다는 얘...</td>\n",
       "      <td>11-converted.ogg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>그런데 외국사람이결국은 집 이사 이제 세방을 얻어 는데 그때 50 전세 한 달에 5...</td>\n",
       "      <td>12-converted.ogg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>회원 가입을 했거든요 하신다하는 건가요?혹시 방법을 높여야 하는지 잘 몰라서 보는데...</td>\n",
       "      <td>95-converted.ogg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>근데 이제 장소가 이제 구애가 없다고 하시면 저희가 그을지로 고용노동부건물에 있는 ...</td>\n",
       "      <td>96-converted.ogg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>감사합니다.확인 도와드릴 텐데 방송한 기다려 주시겠어요?여기야 기자 감사드리고요.거...</td>\n",
       "      <td>97-converted.ogg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>네 감사합니다.저 인사담당자신청했는데요 그 a니까 아직도 않았어요?네 감사합니다.</td>\n",
       "      <td>98-converted.ogg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>감사합니다.결과 지가 아직 않았어요.그래도 매일 두고 가 잘못돼서 그런 것 같아요....</td>\n",
       "      <td>99-converted.ogg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  txt                wav  \\\n",
       "0   내가 나한테 잘해주면 돼요.혹시 여러분들 자식들가운데?지금 손자 손녀키운다고 먹고 ...    1-converted.ogg   \n",
       "1   운명을 바꿔 놓습니다.서울대 음대를 나왔는데요.서울대가 중요한 게 아닙니다.결국 이...   10-converted.ogg   \n",
       "2   네, 감사합니다.네, 감사합니다.서울대 면접없는 판 모국입니다 검사대 여름말씀이신건...  100-converted.ogg   \n",
       "3   그러나 인류는 절대 내가 내 말에 절대 라는 용어를 여간 해서는 절대 안 된다는 얘...   11-converted.ogg   \n",
       "4   그런데 외국사람이결국은 집 이사 이제 세방을 얻어 는데 그때 50 전세 한 달에 5...   12-converted.ogg   \n",
       "..                                                ...                ...   \n",
       "95  회원 가입을 했거든요 하신다하는 건가요?혹시 방법을 높여야 하는지 잘 몰라서 보는데...   95-converted.ogg   \n",
       "96  근데 이제 장소가 이제 구애가 없다고 하시면 저희가 그을지로 고용노동부건물에 있는 ...   96-converted.ogg   \n",
       "97  감사합니다.확인 도와드릴 텐데 방송한 기다려 주시겠어요?여기야 기자 감사드리고요.거...   97-converted.ogg   \n",
       "98      네 감사합니다.저 인사담당자신청했는데요 그 a니까 아직도 않았어요?네 감사합니다.   98-converted.ogg   \n",
       "99  감사합니다.결과 지가 아직 않았어요.그래도 매일 두고 가 잘못돼서 그런 것 같아요....   99-converted.ogg   \n",
       "\n",
       "    voice_fishing  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "95              0  \n",
       "96              0  \n",
       "97              0  \n",
       "98              0  \n",
       "99              0  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 일반 음성 데이터 불러오기 및 라벨링\n",
    "\n",
    "os.chdir('/Users/medici/Downloads/json')\n",
    "text_dir = '/Users/medici/Downloads/json/'\n",
    "\n",
    "voice_spam_text = [f for f in os.listdir()]\n",
    "# JSON 파일 열기\n",
    "d = []\n",
    "for k,file in enumerate(voice_spam_text):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    d.append('')\n",
    "    for i in range(len(data['Transcript'])):\n",
    "        try:\n",
    "            d[k]= d[k]+data['Transcript'][2*i-1]['Content']\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "\n",
    "d = pd.DataFrame(d)\n",
    "normal_dir = '/Users/medici/Downloads/일반대화 음성/'\n",
    "normal_files = os.listdir(normal_dir)\n",
    "d['wav'] = normal_files\n",
    "normal= d\n",
    "normal.rename(columns={0:'txt'},inplace=True)\n",
    "normal['voice_fishing']=0\n",
    "normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "109a6178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>wav</th>\n",
       "      <th>voice_fishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지금 전국적으로 약 이백 여명이 넘게 연료가 되어 있는 사건이고 일단 저희도 어느 ...</td>\n",
       "      <td>1-1-converted.ogg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>금융사기사건이었습니다네.직접 방문하셔서 개설하신.금융권은 어디 금융권들이 있으시죠?...</td>\n",
       "      <td>1-2-converted.ogg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그럼 최근 삼 년 사이에 본인개인정보가 담긴 물품 분실하신 적 전혀 없으십니까?제가...</td>\n",
       "      <td>1-3-converted.ogg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>사실 있는 그대로만 진술하시면 되시는데 현재 계신 곳이 직장 이십니까.통합 불편하시...</td>\n",
       "      <td>1-4-converted.ogg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>일단 이 두 통장은 범죄로 사용돼서 추가적인 피해자가 발생하지 않도록 본인 의사와 ...</td>\n",
       "      <td>1-5-converted.ogg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>많은 분들이 연루돼 있는 부분들가운데서 저희가 지금 동시에 수사를 진행하다 보니까 ...</td>\n",
       "      <td>9-4.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>이렇게 지금 전화 받아 가지고 있던 말아무도 본인이 지금 왜 보려는 전에 는지 본회...</td>\n",
       "      <td>9-5.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>이제 최종 처리를 포함한 공범들하고는 이제 발견된 연관성이 없었기 때문에 일차적인 ...</td>\n",
       "      <td>9-6.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>사건 으로 외모되셨으면 확인 한번 부탁드립니다.네 오세요.서울중앙지검에 김진수 아닙...</td>\n",
       "      <td>9-7.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>일단 저희가 연락을 드린 이유가 혹시 본인께서 통장을 직접 개설하셔서 다른 제 삼자...</td>\n",
       "      <td>9-8.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  txt                wav  \\\n",
       "0   지금 전국적으로 약 이백 여명이 넘게 연료가 되어 있는 사건이고 일단 저희도 어느 ...  1-1-converted.ogg   \n",
       "1   금융사기사건이었습니다네.직접 방문하셔서 개설하신.금융권은 어디 금융권들이 있으시죠?...  1-2-converted.ogg   \n",
       "2   그럼 최근 삼 년 사이에 본인개인정보가 담긴 물품 분실하신 적 전혀 없으십니까?제가...  1-3-converted.ogg   \n",
       "3   사실 있는 그대로만 진술하시면 되시는데 현재 계신 곳이 직장 이십니까.통합 불편하시...  1-4-converted.ogg   \n",
       "4   일단 이 두 통장은 범죄로 사용돼서 추가적인 피해자가 발생하지 않도록 본인 의사와 ...  1-5-converted.ogg   \n",
       "..                                                ...                ...   \n",
       "77  많은 분들이 연루돼 있는 부분들가운데서 저희가 지금 동시에 수사를 진행하다 보니까 ...            9-4.wav   \n",
       "78  이렇게 지금 전화 받아 가지고 있던 말아무도 본인이 지금 왜 보려는 전에 는지 본회...            9-5.wav   \n",
       "79  이제 최종 처리를 포함한 공범들하고는 이제 발견된 연관성이 없었기 때문에 일차적인 ...            9-6.wav   \n",
       "80  사건 으로 외모되셨으면 확인 한번 부탁드립니다.네 오세요.서울중앙지검에 김진수 아닙...            9-7.wav   \n",
       "81  일단 저희가 연락을 드린 이유가 혹시 본인께서 통장을 직접 개설하셔서 다른 제 삼자...            9-8.wav   \n",
       "\n",
       "    voice_fishing  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "..            ...  \n",
       "77              1  \n",
       "78              1  \n",
       "79              1  \n",
       "80              1  \n",
       "81              1  \n",
       "\n",
       "[82 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 보이스피싱 데이터 불러오기 및 라벨링 \n",
    "\n",
    "os.chdir('/Users/medici/Downloads/보이스피싱 json')\n",
    "text_dir = '/Users/medici/Downloads/보이스피싱 json/'\n",
    "\n",
    "voice_spam_text = [f for f in os.listdir()]\n",
    "# JSON 파일 열기\n",
    "d = []\n",
    "for k,file in enumerate(voice_spam_text):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    d.append('')\n",
    "    for i in range(len(data['Transcript'])):\n",
    "        try:\n",
    "            d[k]= d[k]+data['Transcript'][2*i-1]['Content']\n",
    "        except IndexError:\n",
    "            pass\n",
    "d = pd.DataFrame(d)\n",
    "voice_dir = '/Users/medici/Downloads/보이스피싱 음성/'\n",
    "voice_files = os.listdir(voice_dir)\n",
    "d['wav'] = voice_files\n",
    "voice= d\n",
    "voice.rename(columns={0:'txt'},inplace=True)\n",
    "voice['voice_fishing']=1\n",
    "\n",
    "voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d3a8a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([voice,normal],axis=0)\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "638e5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav 데이터 mfcc로 수치화\n",
    "\n",
    "voice_spam_dir = '/Users/medici/Downloads/보이스피싱 음성/'\n",
    "normal_dir = '/Users/medici/Downloads/일반대화 음성/'\n",
    "df['filepath']=''\n",
    "df['voice_feature']=''\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df.at[i,'voice_fishing']==1:\n",
    "        df.at[i,'filepath'] = os.path.join(voice_spam_dir, df.at[i,'wav'])\n",
    "        y, sr = librosa.load(df.at[i,'filepath'], sr=22050)\n",
    "        y = librosa.util.normalize(y)  # 음량 조정\n",
    "        mfccs1 = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        mfccs_mean1 = np.mean(mfccs1, axis=1)\n",
    "        df.at[i,'voice_feature'] = mfccs_mean1\n",
    "\n",
    "    else:\n",
    "        df.at[i,'filepath'] = os.path.join(normal_dir, df.at[i,'wav'])\n",
    "        y, sr = librosa.load(df.at[i,'filepath'], sr=22050)\n",
    "        y = librosa.util.normalize(y)  # 음량 조정\n",
    "        mfccs1 = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        mfccs_mean1 = np.mean(mfccs1, axis=1)\n",
    "        df.at[i,'voice_feature'] = mfccs_mean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "317585f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>wav</th>\n",
       "      <th>voice_fishing</th>\n",
       "      <th>filepath</th>\n",
       "      <th>voice_feature</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지금 전국적으로 약 이백 여명이 넘게 연료가 되어 있는 사건이고 일단 저희도 어느 ...</td>\n",
       "      <td>1-1-converted.ogg</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/medici/Downloads/보이스피싱 음성/1-1-converted...</td>\n",
       "      <td>[-329.98514, 126.196266, -32.76896, 11.3803215...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150224</td>\n",
       "      <td>0.049030</td>\n",
       "      <td>0.287916</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>금융사기사건이었습니다네.직접 방문하셔서 개설하신.금융권은 어디 금융권들이 있으시죠?...</td>\n",
       "      <td>1-2-converted.ogg</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/medici/Downloads/보이스피싱 음성/1-2-converted...</td>\n",
       "      <td>[-316.93973, 157.07793, -23.155636, 8.142115, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224003</td>\n",
       "      <td>0.18568</td>\n",
       "      <td>0.303455</td>\n",
       "      <td>0.169637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt                wav  \\\n",
       "0  지금 전국적으로 약 이백 여명이 넘게 연료가 되어 있는 사건이고 일단 저희도 어느 ...  1-1-converted.ogg   \n",
       "1  금융사기사건이었습니다네.직접 방문하셔서 개설하신.금융권은 어디 금융권들이 있으시죠?...  1-2-converted.ogg   \n",
       "\n",
       "   voice_fishing                                           filepath  \\\n",
       "0              1  /Users/medici/Downloads/보이스피싱 음성/1-1-converted...   \n",
       "1              1  /Users/medici/Downloads/보이스피싱 음성/1-2-converted...   \n",
       "\n",
       "                                       voice_feature    0    1    2    3  \\\n",
       "0  [-329.98514, 126.196266, -32.76896, 11.3803215...  0.0  0.0  0.0  0.0   \n",
       "1  [-316.93973, 157.07793, -23.155636, 8.142115, ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "          4  ...        40        41        42        43       44        45  \\\n",
       "0  0.000000  ...  0.150224  0.049030  0.287916  0.235100  0.00000  0.000000   \n",
       "1  0.476662  ...  0.000000  0.140148  0.000000  0.224003  0.18568  0.303455   \n",
       "\n",
       "         46        47   48        49  \n",
       "0  0.000000  0.051535  0.0  0.056934  \n",
       "1  0.169637  0.000000  0.0  0.000000  \n",
       "\n",
       "[2 rows x 55 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# txt 데이터 TF-IDF로 수치화\n",
    "\n",
    "temp=list(df['txt'])\n",
    "\n",
    "df['txt_feature']=''\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=50,lowercase=False) # TF-IDF 상위 50개 추출\n",
    "for i in range(len(df)):\n",
    "    df.at[i,'txt_feature'] = vectorizer.fit_transform(temp)[i]\n",
    "\n",
    "a=pd.DataFrame()\n",
    "for i in range(len(df)):\n",
    "    b=pd.DataFrame(df.at[i,'txt_feature'].todense())\n",
    "    a=pd.concat([a,b],axis=0)\n",
    "a.reset_index(drop=True,inplace=True)\n",
    "df =pd.concat([df,a],axis=1)\n",
    "df=df.drop(columns='txt_feature')\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "96f5568b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보이스피싱 중요도 TOP50 :\n",
      "내가: 2.8421903228549468\n",
      "우리: 2.8082887711792655\n",
      "본인께서: 2.6541380913520074\n",
      "연락을: 2.5718999931150353\n",
      "이거: 2.5206066987274847\n",
      "저는: 2.4718165345580525\n",
      "직접: 2.4718165345580525\n",
      "그러니까: 2.4482860371478585\n",
      "됩니다: 2.4482860371478585\n",
      "오늘: 2.42529651892316\n",
      "본인이: 2.42529651892316\n",
      "그런데: 2.42529651892316\n",
      "되어: 2.402823663071101\n",
      "바로: 2.3382851419335298\n",
      "가지고: 2.3382851419335298\n",
      "어떻게: 2.297463147413275\n",
      "그런: 2.277660520117095\n",
      "그러면: 2.277660520117095\n",
      "많이: 2.2582424342599934\n",
      "본인: 2.2582424342599934\n",
      "하는: 2.2582424342599934\n",
      "대해서: 2.2582424342599934\n",
      "어떤: 2.239194239289299\n",
      "가지: 2.239194239289299\n",
      "이게: 2.220502106277147\n",
      "그냥: 2.220502106277147\n",
      "다른: 2.20215296760895\n",
      "있어요: 2.1841344621062717\n",
      "해서: 2.1841344621062717\n",
      "일단: 2.1841344621062717\n",
      "같은: 2.166434885006871\n",
      "혹시: 2.166434885006871\n",
      "있습니다: 2.11514159061932\n",
      "겁니다: 2.11514159061932\n",
      "근데: 2.0823517677963297\n",
      "되는: 2.0350988829457837\n",
      "이런: 2.0350988829457837\n",
      "하고: 2.0198314108149953\n",
      "거예요: 1.960990910792062\n",
      "한번: 1.960990910792062\n",
      "저희: 1.9054210596372512\n",
      "저희가: 1.865680730987737\n",
      "그리고: 1.8527773261518292\n",
      "이제: 1.7321493383632145\n",
      "이렇게: 1.7321493383632145\n",
      "그래서: 1.666191370571417\n",
      "제가: 1.5650952537000482\n",
      "때문에: 1.5555258026838976\n",
      "있는: 1.5181382706122772\n",
      "지금: 1.4909872815463263\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF 상위 50개 값 확인\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=50, lowercase=False)\n",
    "# 보이스피싱 텍스트에서 상위 50개의 tf-idf 텍스트와 해당 값출력\n",
    "voice_tfidf = vectorizer.fit_transform(temp)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "indices = np.argsort(vectorizer.idf_)[::-1]\n",
    "top_n = 50\n",
    "top_features = [feature_names[i] for i in indices]\n",
    "top_scores = [vectorizer.idf_[i] for i in indices]\n",
    "print(\"보이스피싱 중요도 TOP50 :\")\n",
    "for i in range(top_n):\n",
    "    print(f\"{top_features[i]}: {top_scores[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f14e1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "91\n",
      "RandomForest:\n",
      "Accuracy: 0.8681318681318682\n",
      "Recall: 0.8095238095238095\n",
      " \n",
      "GradientBoosting:\n",
      "Accuracy: 0.9230769230769231\n",
      "Recall: 0.8571428571428571\n",
      " \n",
      "XGBoost:\n",
      "Accuracy: 0.9230769230769231\n",
      "Recall: 0.8571428571428571\n",
      " \n",
      "LightGBM:\n",
      "Accuracy: 0.9230769230769231\n",
      "Recall: 0.8809523809523809\n"
     ]
    }
   ],
   "source": [
    "# 음성 데이터 학습\n",
    "\n",
    "df_temp=df.drop(columns=['txt','wav','voice_fishing','filepath'])\n",
    "X = df_temp\n",
    "y = df['voice_fishing']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.5,random_state= 18)\n",
    "X_train1=list(X_train['voice_feature'])\n",
    "X_test1=list(X_test['voice_feature'])\n",
    "y_train1 = list(y_train)\n",
    "y_test1 = list(y_test)\n",
    "print(len(X_train1))\n",
    "print(len(y_train1))\n",
    "\n",
    "# randomforest\n",
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "rf.fit(X_train1, y_train1)\n",
    "y_pred_rf = rf.predict(X_test1)\n",
    "print(\"RandomForest:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test1, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test1, y_pred_rf))\n",
    "print(' ')\n",
    "# gradient boosting\n",
    "gb = GradientBoostingClassifier(n_estimators=100)\n",
    "gb.fit(X_train1, y_train1)\n",
    "y_pred_gb = gb.predict(X_test1)\n",
    "print(\"GradientBoosting:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test1, y_pred_gb))\n",
    "print(\"Recall:\", recall_score(y_test1, y_pred_gb))\n",
    "print(' ')\n",
    "# xgboost\n",
    "xgb = XGBClassifier(n_estimators=100,n_jobs=-1)\n",
    "xgb.fit(X_train1, y_train1)\n",
    "y_pred_xgb = xgb.predict(X_test1)\n",
    "print(\"XGBoost:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test1, y_pred_xgb))\n",
    "print(\"Recall:\", recall_score(y_test1, y_pred_xgb))\n",
    "print(' ')\n",
    "# Lightgbm\n",
    "lgbm = LGBMClassifier(n_estimators=100,n_jobs=-1)\n",
    "lgbm.fit(X_train1, y_train1)\n",
    "y_pred_lgbm = lgbm.predict(X_test1)\n",
    "print(\"LightGBM:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test1, y_pred_lgbm))\n",
    "print(\"Recall:\", recall_score(y_test1, y_pred_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d0caf868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble Recall: 0.8809523809523809\n",
      "Accuracy: 0.9340659340659341\n"
     ]
    }
   ],
   "source": [
    "# 음성 모델 ensemble\n",
    "\n",
    "ensemble_wav = VotingClassifier(estimators=[('rf', rf), ('gb', gb), ('xgb', xgb), ('lgbm', lgbm)], voting='soft')\n",
    "ensemble_wav.fit(X_train1, y_train1)\n",
    "y_pred1 = ensemble_wav.predict(X_test1)\n",
    "\n",
    "print(\"ensemble Recall:\", recall_score(y_test1, y_pred1))\n",
    "print(\"Accuracy:\", accuracy_score(y_test1, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7949e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3c7ae05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "91\n",
      "RandomForest:\n",
      "Accuracy: 0.9230769230769231\n",
      "Recall: 0.9047619047619048\n",
      " \n",
      "GradientBoosting:\n",
      "Accuracy: 0.8681318681318682\n",
      "Recall: 0.8333333333333334\n",
      " \n",
      "XGBoost:\n",
      "Accuracy: 0.9340659340659341\n",
      "Recall: 0.9047619047619048\n",
      " \n",
      "LightGBM:\n",
      "Accuracy: 0.9230769230769231\n",
      "Recall: 0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 데이터 학습\n",
    "\n",
    "X_train2=X_train.drop(columns='voice_feature')\n",
    "X_test2=X_test.drop(columns='voice_feature')\n",
    "y_train2 = list(y_train)\n",
    "y_test2 = list(y_test)\n",
    "print(len(X_train2))\n",
    "print(len(y_train2))\n",
    "\n",
    "# randomforest\n",
    "rf_text = RandomForestClassifier(n_estimators=100,n_jobs=-1, max_features=50)\n",
    "rf_text.fit(X_train2, y_train2)\n",
    "y_pred_rf = rf_text.predict(X_test2)\n",
    "print(\"RandomForest:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test2, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test2, y_pred_rf))\n",
    "print(' ')\n",
    "# gradient boosting\n",
    "gb_text = GradientBoostingClassifier(n_estimators=100)\n",
    "gb_text.fit(X_train2, y_train2)\n",
    "y_pred_gb = gb_text.predict(X_test2)\n",
    "print(\"GradientBoosting:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test2, y_pred_gb))\n",
    "print(\"Recall:\", recall_score(y_test2, y_pred_gb))\n",
    "print(' ')\n",
    "# xgboost\n",
    "xgb_text = XGBClassifier(n_estimators=100,n_jobs=-1)\n",
    "xgb_text.fit(X_train2, y_train2)\n",
    "y_pred_xgb = xgb_text.predict(X_test2)\n",
    "print(\"XGBoost:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test2, y_pred_xgb))\n",
    "print(\"Recall:\", recall_score(y_test2, y_pred_xgb))\n",
    "print(' ')\n",
    "# Lightgbm\n",
    "lgbm_text = LGBMClassifier(n_estimators=100,n_jobs=-1)\n",
    "lgbm_text.fit(X_train2, y_train2)\n",
    "y_pred_lgbm = lgbm_text.predict(X_test2)\n",
    "print(\"LightGBM:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test2, y_pred_lgbm))\n",
    "print(\"Recall:\", recall_score(y_test2, y_pred_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "669d9e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble Recall: 0.9047619047619048\n",
      "Accuracy: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 모델 ensemble\n",
    "ensemble_txt = VotingClassifier(estimators=[('rf', rf_text), ('gb', gb_text), ('xgb', xgb_text), ('lgbm', lgbm_text)], voting='soft')\n",
    "ensemble_txt.fit(X_train2, y_train2)\n",
    "y_pred2 = ensemble_txt.predict(X_test2)\n",
    "\n",
    "print(\"ensemble Recall:\", recall_score(y_test2, y_pred2))\n",
    "print(\"Accuracy:\", accuracy_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "53d673f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest:\n",
      "Accuracy: 0.9230769230769231\n",
      "Recall: 0.8809523809523809\n",
      " \n",
      "GradientBoosting:\n",
      "Accuracy: 0.9120879120879121\n",
      "Recall: 0.9047619047619048\n",
      " \n",
      "XGBoost:\n",
      "Accuracy: 0.9230769230769231\n",
      "Recall: 0.8571428571428571\n",
      " \n",
      "LightGBM:\n",
      "Accuracy: 0.9010989010989011\n",
      "Recall: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# 음성과 텍스트 동시에 학습\n",
    "\n",
    "tt = pd.DataFrame(X_test1)\n",
    "X_test3 = X_test.drop(columns='voice_feature')\n",
    "X_test3.reset_index(drop=True,inplace=True)\n",
    "X_test3 = pd.concat([tt,X_test3],axis=1)\n",
    "ttt = pd.DataFrame(X_train1)\n",
    "X_train3 = X_train.drop(columns='voice_feature')\n",
    "X_train3.reset_index(drop=True,inplace=True)\n",
    "X_train3 = pd.concat([ttt,X_train3],axis=1)\n",
    "\n",
    "\n",
    "y_train3 = y_train\n",
    "y_test3 = y_test\n",
    "\n",
    "ss = list(range(90))\n",
    "\n",
    "X_train3.columns=ss\n",
    "X_test3.columns=ss\n",
    "\n",
    "\n",
    "# randomforest\n",
    "rf_f = RandomForestClassifier(n_estimators=100,n_jobs=-1,max_features=90)\n",
    "rf_f.fit(X_train3, y_train3)\n",
    "y_pred_rf = rf_f.predict(X_test3)\n",
    "print(\"RandomForest:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test3, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test3, y_pred_rf))\n",
    "print(' ')\n",
    "# gradient boosting\n",
    "gb_f = GradientBoostingClassifier(n_estimators=100)\n",
    "gb_f.fit(X_train3, y_train3)\n",
    "y_pred_gb = gb_f.predict(X_test3)\n",
    "print(\"GradientBoosting:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test3, y_pred_gb))\n",
    "print(\"Recall:\", recall_score(y_test3, y_pred_gb))\n",
    "print(' ')\n",
    "# xgboost\n",
    "xgb_f = XGBClassifier(n_estimators=100,n_jobs=-1)\n",
    "xgb_f.fit(X_train3, y_train3)\n",
    "y_pred_xgb = xgb_f.predict(X_test3)\n",
    "print(\"XGBoost:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test3, y_pred_xgb))\n",
    "print(\"Recall:\", recall_score(y_test3, y_pred_xgb))\n",
    "print(' ')\n",
    "# Lightgbm\n",
    "lgbm_f = LGBMClassifier(n_estimators=100,n_jobs=-1)\n",
    "lgbm_f.fit(X_train3, y_train3)\n",
    "y_pred_lgbm = lgbm_f.predict(X_test3)\n",
    "print(\"LightGBM:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test3, y_pred_lgbm))\n",
    "print(\"Recall:\", recall_score(y_test3, y_pred_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "65c90565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble Recall: 0.9047619047619048\n",
      "Accuracy: 0.9340659340659341\n"
     ]
    }
   ],
   "source": [
    "# 음성과 텍스트 동시 모델 ensemble\n",
    "ensemble_f = VotingClassifier(estimators=[('rf', rf_f), ('gb', gb_f), ('xgb', xgb_f), ('lgbm', lgbm_f)], voting='soft')\n",
    "ensemble_f.fit(X_train3, y_train3)\n",
    "y_pred3 = ensemble_f.predict(X_test3)\n",
    "\n",
    "print(\"ensemble Recall:\", recall_score(y_test3, y_pred3))\n",
    "print(\"Accuracy:\", accuracy_score(y_test3, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb657105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b6ec7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548d0294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23902275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d33594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b710a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "34730d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>voice_fishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지금 전국적으로 약 이백 여명이 넘게 연료가 되어 있는 사건이고 일단 저희도 어느 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>금융사기사건이었습니다네.직접 방문하셔서 개설하신.금융권은 어디 금융권들이 있으시죠?...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그럼 최근 삼 년 사이에 본인개인정보가 담긴 물품 분실하신 적 전혀 없으십니까?제가...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>사실 있는 그대로만 진술하시면 되시는데 현재 계신 곳이 직장 이십니까.통합 불편하시...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>일단 이 두 통장은 범죄로 사용돼서 추가적인 피해자가 발생하지 않도록 본인 의사와 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>회원 가입을 했거든요 하신다하는 건가요?혹시 방법을 높여야 하는지 잘 몰라서 보는데...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>근데 이제 장소가 이제 구애가 없다고 하시면 저희가 그을지로 고용노동부건물에 있는 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>감사합니다.확인 도와드릴 텐데 방송한 기다려 주시겠어요?여기야 기자 감사드리고요.거...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>네 감사합니다.저 인사담당자신청했는데요 그 a니까 아직도 않았어요?네 감사합니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>감사합니다.결과 지가 아직 않았어요.그래도 매일 두고 가 잘못돼서 그런 것 같아요....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   txt  voice_fishing\n",
       "0    지금 전국적으로 약 이백 여명이 넘게 연료가 되어 있는 사건이고 일단 저희도 어느 ...              1\n",
       "1    금융사기사건이었습니다네.직접 방문하셔서 개설하신.금융권은 어디 금융권들이 있으시죠?...              1\n",
       "2    그럼 최근 삼 년 사이에 본인개인정보가 담긴 물품 분실하신 적 전혀 없으십니까?제가...              1\n",
       "3    사실 있는 그대로만 진술하시면 되시는데 현재 계신 곳이 직장 이십니까.통합 불편하시...              1\n",
       "4    일단 이 두 통장은 범죄로 사용돼서 추가적인 피해자가 발생하지 않도록 본인 의사와 ...              1\n",
       "..                                                 ...            ...\n",
       "177  회원 가입을 했거든요 하신다하는 건가요?혹시 방법을 높여야 하는지 잘 몰라서 보는데...              0\n",
       "178  근데 이제 장소가 이제 구애가 없다고 하시면 저희가 그을지로 고용노동부건물에 있는 ...              0\n",
       "179  감사합니다.확인 도와드릴 텐데 방송한 기다려 주시겠어요?여기야 기자 감사드리고요.거...              0\n",
       "180      네 감사합니다.저 인사담당자신청했는데요 그 a니까 아직도 않았어요?네 감사합니다.              0\n",
       "181  감사합니다.결과 지가 아직 않았어요.그래도 매일 두고 가 잘못돼서 그런 것 같아요....              0\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum = pd.concat([voice,normal])\n",
    "df_sum = df_sum.drop(columns='wav')\n",
    "df_sum= df_sum.reset_index(drop=True)\n",
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9cfa83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 정의\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','요','.','께서','에서','이다','되다']\n",
    "\n",
    "# 토큰화 \n",
    "okt = Okt()\n",
    "tokenized_data = []\n",
    "for sentence in df_sum['txt']:\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    tokenized_data.append(temp_X)\n",
    "\n",
    "# Word2vec 모델 학습\n",
    "model = Word2Vec(sentences = tokenized_data, window = 5, min_count = 1, workers = 4, sg = 0)\n",
    "model.wv.vectors.shape\n",
    "\n",
    "# 각 문장의 벡터 표현 생성\n",
    "sentence_vectors = []\n",
    "for text in tokenized_data:\n",
    "    vector = np.mean([model.wv[word] for word in text], axis=0)\n",
    "    sentence_vectors.append(vector)\n",
    "\n",
    "labels = list(df_sum['voice_fishing'])\n",
    "X_train,X_test,y_train,y_test = train_test_split(sentence_vectors,labels,test_size = 0.5,random_state= 17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "77a902fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest:\n",
      "Accuracy: 0.8681318681318682\n",
      "Recall: 0.9354838709677419\n",
      " \n",
      "GradientBoosting:\n",
      "Accuracy: 0.8571428571428571\n",
      "Recall: 0.8387096774193549\n",
      " \n",
      "XGBoost:\n",
      "Accuracy: 0.8571428571428571\n",
      "Recall: 0.8387096774193549\n",
      " \n",
      "LightGBM:\n",
      "Accuracy: 0.8681318681318682\n",
      "Recall: 0.8387096774193549\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec을 통한 모델 학습\n",
    "\n",
    "# randomforest\n",
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"RandomForest:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(' ')\n",
    "# gradient boosting\n",
    "gb = GradientBoostingClassifier(n_estimators=100)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "print(\"GradientBoosting:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_gb))\n",
    "print(' ')\n",
    "# xgboost\n",
    "xgb = XGBClassifier(n_estimators=100,n_jobs=-1)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(\"XGBoost:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_xgb))\n",
    "print(' ')\n",
    "# Lightgbm\n",
    "lgbm = LGBMClassifier(n_estimators=100,n_jobs=-1)\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_pred_lgbm = lgbm.predict(X_test)\n",
    "print(\"LightGBM:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lgbm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0160d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21154b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e8302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
